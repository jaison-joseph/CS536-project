

ITGSend -a <receiver_ip> -T UDP -c 100 -C 10 -t 60000 -l sender.log -x receiver.log
ITGSend -a 10.0.0.1 -T UDP -c 100 -C 10 -t 60000 -l sender.log -x receiver.log

mininet> h1 ITGRecv &
mininet> h2 ITGSend -a 10.0.0.1 -T UDP -c 100 -C 10 -t 60000 -l sender.log -x receiver.log
     -c is packet size (default 512 bytes)
    -C packet send rate default is 1000 pkts/s
    -t duration in ms
	-E: mean of exponential distribution for ITGSend to use for traffic rate
...
mininet> h2 ITGDec receiver.log > receiver-decoded.txt

-k for itgsend 

h2 ITGDec sender.log -d 1000 delay.txt -p 1000 loss.txt -c 1000 avg.txt

ITGDec with -c <CT> [filename]  will give average stats 
  -c <CT> [filename]   Print all average metrics to file every <CT> milliseconds
                       (default filename: 'combined_stats.dat').

                       Dumps to file all the average metrics as sampled every <PT> milliseconds.
                       Each line of the output file respectively contains the follwing fields:
                       - "Time", "Bitrate", "Delay", "Jitter", "Packet loss"

    source: https://traffic.comics.unina.it/software/ITG/manual/index.html#SECTION00045000000000000000

with ditgsend, we can use a -Fs option to specify packet sizes of our choice. we can use 


Link capacities range the following values: 10, 40 or
100 kbps.

the receiver log has the useful information. 


def run_tests(net):
	from datetime import datetime
	
	h1, h2, h3, h4 = net.get('h1', 'h2', 'h3', 'h4')	
	timestamp = datetime.now().strftime('%Y-%m-%d-%H:%M:%S.%f')

	h1.cmd(f'ITGRecv &')
	h2.cmd(f'ITGSend -a 10.0.0.1 -T UDP -c 100 -C 10 -t 10000 -x itg/h2-receiver.log')


------------------------------------------------------------------------------------------------------------

RouteNet takes as input 
(i) a given topology,
(ii) a source-destination routing scheme (i.e., list of end-to-end paths)
(iii) a traffic matrix (defined as the bandwidth between each node pair in the network), 

and produces as output: 
performance metrics according to the current network state (per-path mean delay, jitter, and packet loss)

------------------------------------------------------------------------------------------------------------

roadmap

input: 	number of hosts, number of switches, "kind" of topology
to: 	topology generator 
output: topology description 
			(hosts, switches, links between switches, what switch a host is connected to, link speed between nodes)
		and 
		ONOS config file
		and
		get-hops.sh
-- main.py & main_extension.py

input: 	mininet topology file, ONOS config file, get-hops.sh
to:		mininet + ONOS 
output: hops.txt

input: 	mininet topology file & hops.txt
to: 	generateTrafficMatrix
otuput: traffic matrix
-- generateTrafficMatrix

input: 	mininet topology file + traffic matrix
to: 	main.py
output:	test file 

(new shell) create the container named "onos" with "make controller"
wait 15 seconds
(new shell) create the container named "mn-stratum" with "make mininet"
wait 5 seconds
(new shell) create the container named "onos-cli" with "make cli"
	it will start the ONOS shell and prompt for a password. Enter "rocks", then hit enteer
	wait for 5 seconds
	then, in the ONOS shell, run "app activate fwd"
wait 2 seconds
	(new shell) just run, from another host terminal/shell "make netcfg"
wait 5 seconds,
	from the container "mn-stratum" that is running the mininet shell, run "pingall" from the mininet shell
wait 10 seconds
	(new shell) 
		run docker cp get-hops.sh onos:/root/onos/get-hops.sh
		enter the ONOS container with:  docker exec -it onos bash
		run get-hops.sh
		copy the results back to the host at host location: /home/ubuntu/assignment0/public/assignments/temp-test/CS536-project/hops.txt

echo "(s1, s2): $(paths device:s1 device:s2)" >> paths.txt
echo "(s1, s3): $(paths device:s1 device:s3)" >> paths.txt
echo "(s1, s4): $(paths device:s1 device:s4)" >> paths.txt
echo "(s1, s5): $(paths device:s1 device:s5)" >> paths.txt

docker cp foo.sh onos:/root/onos/foo.sh

itgdec command for script:
h1 ITGDec logs/2024-11-26-06:56:31.872282_0_0_2_0.txt -c 1000 decoded/2024-11-26-06:56:31.872282_0_0_2_0.txt

dirty test for core scripts functionality
python3 main.py 3 3 nsfnet && python3 main_extension.py

Nov 27 TODO

TODO:
	update how we store the results:
		1 folder per simulation
		folder name: {Topology_type}_{No. of Hosts}_{No. of Switches}_{intensity}
			within each simulation folder, we have files for runs:
				run_{run number}
					and within each run folder, we have the following:
						routing.txt
						<date>-<timestamp>_<source node>_<dest node>.txt
							e.g. 2024-11-22-19:09:45.291079_4_1.txt

	Bring back the logic for generating get-hops.sh and hops.txt, 
	
	in the network generator, ensure 1 host/switch

	add the following params to the master script:
		1. Simulation time
		2. How often statistics from simulation will be reported
		3. Traffic intensity
		4. How many times the simulation should be run (edited) 

	update generated mininet config file to limit queue size to 32 packets

	Fix the issue with incomplete results
		1. try removing nohup from the ITGDec commands in the test.py file; this is a cheap command, so just run it sequentially?

	python3 master.py 3 nsfnet 1 30 1000 12

	tmux attach-session -t onos_session

	docker stats mn-stratum onos

	logs on debugging:
	- docker containers are not resource xonstrained
		- monitored while running pingall

	- removed bandwidths on links, didn't help

make controller

export MN_STRATUM_TOPO_FILE=simulations/nsfnet_12_12/custom_topo_original.py
scripts/mn-custom MN_STRATUM_TOPO_FILE=$MN_STRATUM_TOPO_FILE

scripts/onos-cli

export ONOS_CONFIG_FILE=simulations/nsfnet_12_12/onos_config.json
scripts/onos-netcfg $ONOS_CONFIG_FILE

app activate org.onosproject.openflow

ovs switch attempt:

app activate org.onosproject.openflow

start onos
activate apps
launch mininet

py execfile('simulations/nsfnet_12_12/test.py')
py run_tests(net)


TODO Dec 1
	- increase wait for itgsend to 2x test time
	- add wait time for itgdec 

		total wait time: 5 + (2 * testDuration) + 10 + (2 * # of nodes)
			itgrecv start + itgsend + itgrecv kill + itgdec
		# wait for servers to start
        time.sleep(2)
		# wait for ITGSend to finish
        time.sleep(60)
		# wait for killing of ITGRecv processes
        time.sleep(10)
        time.sleep(20)